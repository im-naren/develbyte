"use strict";(self.webpackChunkmy_blog=self.webpackChunkmy_blog||[]).push([[7647],{4522:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>d,contentTitle:()=>o,default:()=>l,frontMatter:()=>n,metadata:()=>r,toc:()=>c});var r=a(4877),i=a(4848),s=a(8453);const n={slug:"hdfs-architecture",title:"HDFS Architecture",authors:["narendra"],tags:["hadoop","hdfs","big-data","architecture"],date:new Date("2015-05-03T00:00:00.000Z")},o="HDFS Architecture",d={authorsImageUrls:[void 0]},c=[];function u(e){const t={p:"p",...(0,s.R)(),...e.components};return(0,i.jsx)(t.p,{children:"The Hadoop Distributed File System (HDFS) is a highly fault tolerant file system designed and optimized to be deployed on a distributed infrastructure established with a bunch commodity hardware. HDFS provides high throughput access to application data and is best suited for applications that have large data sets. Unlike existing distributed file systems HDFS have loosen up a few POSIX Standards to enable streaming access to file system data. HDFS was originally developed as an infrastructure for the Apache Nutch web search engine project."})}function l(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(u,{...e})}):u(e)}},4877:e=>{e.exports=JSON.parse('{"permalink":"/blog/hdfs-architecture","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2015-05-03-hdfs-architecture.md","source":"@site/blog/2015-05-03-hdfs-architecture.md","title":"HDFS Architecture","description":"The Hadoop Distributed File System (HDFS) is a highly fault tolerant file system designed and optimized to be deployed on a distributed infrastructure established with a bunch commodity hardware. HDFS provides high throughput access to application data and is best suited for applications that have large data sets. Unlike existing distributed file systems HDFS have loosen up a few POSIX Standards to enable streaming access to file system data. HDFS was originally developed as an infrastructure for the Apache Nutch web search engine project.","date":"2015-05-03T00:00:00.000Z","tags":[{"inline":true,"label":"hadoop","permalink":"/blog/tags/hadoop"},{"inline":true,"label":"hdfs","permalink":"/blog/tags/hdfs"},{"inline":true,"label":"big-data","permalink":"/blog/tags/big-data"},{"inline":true,"label":"architecture","permalink":"/blog/tags/architecture"}],"readingTime":1.94,"hasTruncateMarker":true,"authors":[{"name":"Narendra Dubey","title":"Builder of Data Systems and Software","url":"https://im-naren.github.io/about/","imageURL":"https://github.com/im-naren.png","key":"narendra","page":null}],"frontMatter":{"slug":"hdfs-architecture","title":"HDFS Architecture","authors":["narendra"],"tags":["hadoop","hdfs","big-data","architecture"],"date":"2015-05-03T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Introduction To MapReduce","permalink":"/blog/introduction-to-mapreduce"},"nextItem":{"title":"MapReduce Execution in Hadoop","permalink":"/blog/mapreduce-execution-in-hadoop"}}')},8453:(e,t,a)=>{a.d(t,{R:()=>n,x:()=>o});var r=a(6540);const i={},s=r.createContext(i);function n(e){const t=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:n(e.components),r.createElement(s.Provider,{value:t},e.children)}}}]);