"use strict";(self.webpackChunkmy_blog=self.webpackChunkmy_blog||[]).push([[1650],{4800:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>p,frontMatter:()=>i,metadata:()=>a,toc:()=>c});var a=n(8645),o=n(4848),r=n(8453);const i={slug:"introduction-to-mapreduce",title:"Introduction To MapReduce",authors:["narendra"],tags:["hadoop","mapreduce","big-data","java"],date:new Date("2015-05-14T00:00:00.000Z")},s="Introduction To MapReduce",l={authorsImageUrls:[void 0]},c=[{value:"Overview",id:"overview",level:2},{value:"Input and Output types of a MapReduce job:",id:"input-and-output-types-of-a-mapreduce-job",level:2},{value:"WordCount.java",id:"wordcountjava",level:2}];function u(e){const t={code:"code",em:"em",h2:"h2",p:"p",pre:"pre",strong:"strong",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)(t.p,{children:[(0,o.jsx)(t.strong,{children:"MapReduce"})," is a framework for processing large amount of data residing on hundreds of computers, its an extraordinarily powerful paradigm. MapReduce was first introduced by Google in 2004 MapReduce: Simplified Data Processing on Large Clusters."]}),"\n",(0,o.jsx)(t.p,{children:"In this article we'll see how MapReduce processes the data, I am considering the Word Count program as a example, yeah!! this is the worlds most famous MapReduce program!!"}),"\n",(0,o.jsx)(t.h2,{id:"overview",children:"Overview"}),"\n",(0,o.jsxs)(t.p,{children:["The MapReduce framework operates exclusively on ",(0,o.jsx)(t.em,{children:"<key, value>"})," pairs, that is, the framework views the input to the job as a set of ",(0,o.jsx)(t.em,{children:"<key, value>"})," pairs and produces a set of ",(0,o.jsx)(t.em,{children:"<key, value>"})," pairs as the output of the job, conceivably of different types."]}),"\n",(0,o.jsx)(t.p,{children:"The key and value classes have to be serializable by the framework and hence need to implement the Writable interface. Additionally, the key classes have to implement the WritableComparable interface to facilitate sorting by the framework."}),"\n",(0,o.jsx)(t.h2,{id:"input-and-output-types-of-a-mapreduce-job",children:"Input and Output types of a MapReduce job:"}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsxs)(t.em,{children:["(input) <k1, v1> -> ",(0,o.jsx)(t.strong,{children:"map"})," -> <k2, v2> -> ",(0,o.jsx)(t.strong,{children:"combine"})," -> <k2, v2> -> ",(0,o.jsx)(t.strong,{children:"reduce"})," -> <k3, v3> (output)"]})}),"\n",(0,o.jsx)(t.h2,{id:"wordcountjava",children:"WordCount.java"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-java",children:'import java.io.IOException;\nimport java.util.*;\n \nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.conf.*;\nimport org.apache.hadoop.io.*;\nimport org.apache.hadoop.mapred.*;\nimport org.apache.hadoop.util.*;\n \npublic class WordCount {\n  public static class Map extends MapReduceBase implements Mapper<LongWritable, Text, Text, IntWritable> {\n    private final static IntWritable one = new IntWritable(1);\n    private Text word = new Text();\n  \n    public void map(LongWritable key, Text value, \n                    OutputCollector<Text, IntWritable> output, \n                    Reporter reporter) throws IOException {\n      String line = value.toString();\n      StringTokenizer tokenizer = new StringTokenizer(line);\n      while (tokenizer.hasMoreTokens()) {\n        word.set(tokenizer.nextToken());\n        output.collect(word, one);\n      }\n    }\n  }\n  \n  public static class Reduce extends MapReduceBase implements Reducer<Text, IntWritable, Text, IntWritable> {\n    public void reduce(Text key, Iterator<IntWritable> values, \n                        OutputCollector<Text, IntWritable> output, \n                        Reporter reporter) throws IOException {\n      int sum = 0;\n      while (values.hasNext()) {\n        sum += values.next().get();\n      }\n      output.collect(key, new IntWritable(sum));\n    }\n  }\n  \n  public static void main(String[] args) throws Exception {\n    JobConf conf = new JobConf(WordCount.class);\n    conf.setJobName("wordcount");\n    \n    conf.setOutputKeyClass(Text.class);\n    conf.setOutputValueClass(IntWritable.class);\n    \n    conf.setMapperClass(Map.class);\n    conf.setCombinerClass(Reduce.class);\n    conf.setReducerClass(Reduce.class);\n    \n    conf.setInputFormat(TextInputFormat.class);\n    conf.setOutputFormat(TextOutputFormat.class);\n    \n    FileInputFormat.setInputPaths(conf, new Path(args[0]));\n    FileOutputFormat.setOutputPath(conf, new Path(args[1]));\n    \n    JobClient.runJob(conf);\n  }\n}\n'})})]})}function p(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(u,{...e})}):u(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>s});var a=n(6540);const o={},r=a.createContext(o);function i(e){const t=a.useContext(r);return a.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),a.createElement(r.Provider,{value:t},e.children)}},8645:e=>{e.exports=JSON.parse('{"permalink":"/develbyte/blog/introduction-to-mapreduce","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2015-05-14-introduction-to-mapreduce.md","source":"@site/blog/2015-05-14-introduction-to-mapreduce.md","title":"Introduction To MapReduce","description":"MapReduce is a framework for processing large amount of data residing on hundreds of computers, its an extraordinarily powerful paradigm. MapReduce was first introduced by Google in 2004 MapReduce: Simplified Data Processing on Large Clusters.","date":"2015-05-14T00:00:00.000Z","tags":[{"inline":false,"label":"Hadoop","permalink":"/develbyte/blog/tags/hadoop","description":"Apache Hadoop ecosystem"},{"inline":false,"label":"MapReduce","permalink":"/develbyte/blog/tags/mapreduce","description":"MapReduce programming model"},{"inline":false,"label":"Big Data","permalink":"/develbyte/blog/tags/big-data","description":"Big data technologies and concepts"},{"inline":false,"label":"Java","permalink":"/develbyte/blog/tags/java","description":"Java programming language"}],"readingTime":1.69,"hasTruncateMarker":false,"authors":[{"name":"Narendra Dubey","title":"Builder of Data Systems and Software","url":"https://im-naren.github.io/about/","page":{"permalink":"/develbyte/blog/authors/narendra"},"socials":{"github":"https://github.com/im-naren","linkedin":"https://www.linkedin.com/in/im-naren/","email":"mailto:naren.dubey@zoho.com"},"imageURL":"https://github.com/im-naren.png","key":"narendra"}],"frontMatter":{"slug":"introduction-to-mapreduce","title":"Introduction To MapReduce","authors":["narendra"],"tags":["hadoop","mapreduce","big-data","java"],"date":"2015-05-14T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"How to Implement Singly Linked List in Java","permalink":"/develbyte/blog/how-to-implement-singly-linked-list-in-java"},"nextItem":{"title":"HDFS Architecture","permalink":"/develbyte/blog/hdfs-architecture"}}')}}]);