"use strict";(self.webpackChunkmy_blog=self.webpackChunkmy_blog||[]).push([[6754],{4156:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>l,frontMatter:()=>r,metadata:()=>i,toc:()=>d});var i=n(5615),a=n(4848),o=n(8453);const r={slug:"mapreduce-execution-in-hadoop",title:"MapReduce Execution in Hadoop",authors:["narendra"],tags:["hadoop","mapreduce","big-data"],date:new Date("2015-03-10T00:00:00.000Z")},s="MapReduce Execution in Hadoop",c={authorsImageUrls:[void 0]},d=[{value:"MapReduce 1 Execution Sequence:",id:"mapreduce-1-execution-sequence",level:2}];function u(e){const t={code:"code",h2:"h2",li:"li",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.p,{children:"In this article we have tried to summaries,  how a MapReduce program executes in Hadoop environment."}),"\n",(0,a.jsx)(t.h2,{id:"mapreduce-1-execution-sequence",children:"MapReduce 1 Execution Sequence:"}),"\n",(0,a.jsx)(t.p,{children:"MapReduce execution starts with below command."}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"Step 1:"})," ",(0,a.jsx)(t.code,{children:"$ hadoop jar <jar> [mainClass] args..."})]}),"\n",(0,a.jsx)(t.p,{children:"This command starts the MapReduce execution in Clients JVM.\ncreates the Job."}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"Step 2:"})," ",(0,a.jsx)(t.code,{children:"JobTracker.getNewJobId()"})]}),"\n",(0,a.jsx)(t.p,{children:"Client Asks JobTracker for a new JobId."}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"Step 3:"})," ",(0,a.jsx)(t.code,{children:"JobClient.SubmitJob() / JobClient.runJob()"})]}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:"Checking the input and output specifications of the job."}),"\n",(0,a.jsx)(t.li,{children:"Computing the InputSplits for the job."}),"\n",(0,a.jsx)(t.li,{children:"Setup the requisite accounting information for the DistributedCache of the job, if necessary."}),"\n",(0,a.jsx)(t.li,{children:"Copying the job's jar and configuration to the JobTracker  file-system, in a folder names as the JobId assigned with very high replication factor(default 10)."}),"\n",(0,a.jsx)(t.li,{children:"Submitting the job to the JobTracker and optionally monitoring it's status."}),"\n",(0,a.jsx)(t.li,{children:"JobTracker puts the job into an internal queue from where JobScheduler will pick it up and Initialize"}),"\n"]}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"Step 4:"})," Initialize the Job"]}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:"Creates an object of the Job."}),"\n",(0,a.jsx)(t.li,{children:"Encapsulates its Tasks."}),"\n",(0,a.jsx)(t.li,{children:"Retrieve the InputSplit and create one map task for each split."}),"\n",(0,a.jsx)(t.li,{children:"Creates the reduces task the number of reduce task depends on the number defined in the driver code(default 1)."}),"\n",(0,a.jsx)(t.li,{children:"Creates a Job Setup task to setup the job before map tasks run."}),"\n",(0,a.jsx)(t.li,{children:"Creates a Job Cleanup task to run after the reducer task run."}),"\n"]})]})}function l(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(u,{...e})}):u(e)}},5615:e=>{e.exports=JSON.parse('{"permalink":"/blog/mapreduce-execution-in-hadoop","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2015-03-10-mapreduce-execution-in-hadoop.md","source":"@site/blog/2015-03-10-mapreduce-execution-in-hadoop.md","title":"MapReduce Execution in Hadoop","description":"In this article we have tried to summaries,  how a MapReduce program executes in Hadoop environment.","date":"2015-03-10T00:00:00.000Z","tags":[{"inline":true,"label":"hadoop","permalink":"/blog/tags/hadoop"},{"inline":true,"label":"mapreduce","permalink":"/blog/tags/mapreduce"},{"inline":true,"label":"big-data","permalink":"/blog/tags/big-data"}],"readingTime":1.08,"hasTruncateMarker":true,"authors":[{"name":"Narendra Dubey","title":"Builder of Data Systems and Software","url":"https://im-naren.github.io/about/","imageURL":"https://github.com/im-naren.png","key":"narendra","page":null}],"frontMatter":{"slug":"mapreduce-execution-in-hadoop","title":"MapReduce Execution in Hadoop","authors":["narendra"],"tags":["hadoop","mapreduce","big-data"],"date":"2015-03-10T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"HDFS Architecture","permalink":"/blog/hdfs-architecture"},"nextItem":{"title":"Difference between Unix and Linux","permalink":"/blog/difference-between-unix-and-linux"}}')},8453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>s});var i=n(6540);const a={},o=i.createContext(a);function r(e){const t=i.useContext(o);return i.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),i.createElement(o.Provider,{value:t},e.children)}}}]);